{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Trend Analysis\n",
    "##### Team Members: Simon, Frank and David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import functools as ft\n",
    "import seaborn as sns\n",
    "import re  \n",
    "from scipy.stats import logistic\n",
    "import calendar\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "youtube_data = pd.read_csv('YouTube_Data/US_youtube_trending_data.csv')\n",
    "lookup = pd.read_csv('YouTube_Data/category_ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Exploration\n",
    "#### Pandas Process\n",
    "\n",
    "* Parse youtube date format into datetime format\n",
    "* Calculate lag time for each video to trend\n",
    "* Replace category ID integers with category names based on youtube category dictionary\n",
    "* Sort by ‘like’, most to least\n",
    "* Drop duplicates\n",
    "* Groupby date, calculate number of trending videos published\n",
    "* Groupby category calculate number, like %, dislike %\n",
    "* Groupby month, see if there are trending difference month-to-month (there are not)\n",
    "* Analyze the lag time for a video to trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse dates (there is probably a built-in function, but this is what I was able to figure out)\n",
    "\n",
    "def youtube_date_parse(df, series_to_parse, new_name_date, new_name_time, delimiting_character, drop_character):\n",
    "    try:\n",
    "        split = df[series_to_parse].str.split(delimiting_character, n = 1, expand = True)\n",
    "        split[1] =split[1].map(lambda x: x.rstrip(drop_character))\n",
    "        df[new_name_date] = split[0]\n",
    "        df[new_name_time] = split[1]\n",
    "        df.drop(columns = [series_to_parse], inplace=True)\n",
    "        df[new_name_date] = pd.to_datetime(df[new_name_date])\n",
    "        return df\n",
    "    except:\n",
    "        print('Already parsed, dumbass...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_published</th>\n",
       "      <th>date_trending</th>\n",
       "      <th>lag</th>\n",
       "      <th>month_published</th>\n",
       "      <th>month_trending</th>\n",
       "      <th>time_published</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>Big Hit Labels</td>\n",
       "      <td>BTS (방탄소년단) 'Dynamite' Official MV</td>\n",
       "      <td>Music</td>\n",
       "      <td>232649205</td>\n",
       "      <td>15735533</td>\n",
       "      <td>714194</td>\n",
       "      <td>6065230</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>7 days</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Aug</td>\n",
       "      <td>03:58:10</td>\n",
       "      <td>BIGHIT|빅히트|방탄소년단|BTS|BANGTAN|방탄</td>\n",
       "      <td>BTS (방탄소년단) 'Dynamite' Official MVCredits:Dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>BLACKPINK - 'Ice Cream (with Selena Gomez)' M/V</td>\n",
       "      <td>Music</td>\n",
       "      <td>184778248</td>\n",
       "      <td>11795670</td>\n",
       "      <td>879354</td>\n",
       "      <td>2735997</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>8 days</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Sept</td>\n",
       "      <td>04:00:11</td>\n",
       "      <td>YG Entertainment|YG|와이지|K-pop|BLACKPINK|블랙핑크|블...</td>\n",
       "      <td>BLACKPINK - ‘Ice Cream (with Selena Gomez)’Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11764</th>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>BLACKPINK – ‘Lovesick Girls’ M/V</td>\n",
       "      <td>Music</td>\n",
       "      <td>140685439</td>\n",
       "      <td>9217876</td>\n",
       "      <td>127308</td>\n",
       "      <td>1507605</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>7 days</td>\n",
       "      <td>Oct</td>\n",
       "      <td>Oct</td>\n",
       "      <td>04:00:13</td>\n",
       "      <td>YG Entertainment|YG|와이지|K-pop|BLACKPINK|블랙핑크|블...</td>\n",
       "      <td>BLACKPINK – ‘Lovesick Girls’영원한 밤창문 없는 방에 우릴 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>Big Hit Labels</td>\n",
       "      <td>BTS (방탄소년단) 'Dynamite' Official Teaser</td>\n",
       "      <td>Music</td>\n",
       "      <td>62496726</td>\n",
       "      <td>6178664</td>\n",
       "      <td>158845</td>\n",
       "      <td>992356</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>7 days</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Aug</td>\n",
       "      <td>15:00:02</td>\n",
       "      <td>BIGHIT|빅히트|방탄소년단|BTS|BANGTAN|방탄</td>\n",
       "      <td>BTS (방탄소년단) 'Dynamite' Official TeaserBTS (방탄소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>Big Hit Labels</td>\n",
       "      <td>BTS (방탄소년단) 'Dynamite' Official MV (B-side)</td>\n",
       "      <td>Music</td>\n",
       "      <td>45596902</td>\n",
       "      <td>5951286</td>\n",
       "      <td>97683</td>\n",
       "      <td>382374</td>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>7 days</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Aug</td>\n",
       "      <td>15:00:01</td>\n",
       "      <td>BIGHIT|빅히트|방탄소년단|BTS|BANGTAN|방탄</td>\n",
       "      <td>BTS (방탄소년단) 'Dynamite' Official MV (B-side)Cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              channel                                            title  \\\n",
       "3358   Big Hit Labels               BTS (방탄소년단) 'Dynamite' Official MV   \n",
       "4980        BLACKPINK  BLACKPINK - 'Ice Cream (with Selena Gomez)' M/V   \n",
       "11764       BLACKPINK                 BLACKPINK – ‘Lovesick Girls’ M/V   \n",
       "2762   Big Hit Labels           BTS (방탄소년단) 'Dynamite' Official Teaser   \n",
       "3992   Big Hit Labels      BTS (방탄소년단) 'Dynamite' Official MV (B-side)   \n",
       "\n",
       "      category      views     likes  dislikes  comments date_published  \\\n",
       "3358     Music  232649205  15735533    714194   6065230     2020-08-21   \n",
       "4980     Music  184778248  11795670    879354   2735997     2020-08-28   \n",
       "11764    Music  140685439   9217876    127308   1507605     2020-10-02   \n",
       "2762     Music   62496726   6178664    158845    992356     2020-08-18   \n",
       "3992     Music   45596902   5951286     97683    382374     2020-08-24   \n",
       "\n",
       "      date_trending    lag month_published month_trending time_published  \\\n",
       "3358     2020-08-28 7 days             Aug            Aug       03:58:10   \n",
       "4980     2020-09-05 8 days             Aug           Sept       04:00:11   \n",
       "11764    2020-10-09 7 days             Oct            Oct       04:00:13   \n",
       "2762     2020-08-25 7 days             Aug            Aug       15:00:02   \n",
       "3992     2020-08-31 7 days             Aug            Aug       15:00:01   \n",
       "\n",
       "                                                    tags  \\\n",
       "3358                     BIGHIT|빅히트|방탄소년단|BTS|BANGTAN|방탄   \n",
       "4980   YG Entertainment|YG|와이지|K-pop|BLACKPINK|블랙핑크|블...   \n",
       "11764  YG Entertainment|YG|와이지|K-pop|BLACKPINK|블랙핑크|블...   \n",
       "2762                     BIGHIT|빅히트|방탄소년단|BTS|BANGTAN|방탄   \n",
       "3992                     BIGHIT|빅히트|방탄소년단|BTS|BANGTAN|방탄   \n",
       "\n",
       "                                             description  \n",
       "3358   BTS (방탄소년단) 'Dynamite' Official MVCredits:Dire...  \n",
       "4980   BLACKPINK - ‘Ice Cream (with Selena Gomez)’Com...  \n",
       "11764  BLACKPINK – ‘Lovesick Girls’영원한 밤창문 없는 방에 우릴 가...  \n",
       "2762   BTS (방탄소년단) 'Dynamite' Official TeaserBTS (방탄소...  \n",
       "3992   BTS (방탄소년단) 'Dynamite' Official MV (B-side)Cre...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Clean up data: drop columns, parse dates, replace category numbers with cateogry names, etc. #####\n",
    "\n",
    "# Drop unneeded columns\n",
    "youtube_data.drop(['video_id','channelId', 'thumbnail_link', 'comments_disabled', 'ratings_disabled'],\\\n",
    "                  axis=1, inplace = True)\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "youtube_date_parse(youtube_data, 'publishedAt', 'date_published', 'time_published', 'T', 'Z')\n",
    "youtube_date_parse(youtube_data, 'trending_date', 'date_trending', 'time_trending', 'T', 'Z')\n",
    "youtube_data.drop(['time_trending'], axis=1, inplace=True)\n",
    "\n",
    "# The datetime functions are great, and can be used to group (see below).\n",
    "# To make life easier for folks, I'm going to put month names in their own column\n",
    "# notice the .dt.month syntax that works on datetime objects\n",
    "youtube_data['month_published']= youtube_data['date_published'].dt.month\n",
    "youtube_data['month_trending'] = youtube_data['date_trending'].dt.month\n",
    "youtube_data['month_published'].replace([8,9,10,11], ['Aug', 'Sept', 'Oct', 'Nov'], inplace=True)\n",
    "youtube_data['month_trending'].replace([8,9,10,11], ['Aug', 'Sept', 'Oct', 'Nov'], inplace=True)\n",
    "\n",
    "# Calculate lag time between posting and trending.  You can do arithmetic with dates in datetime\n",
    "youtube_data['lag'] = youtube_data['date_trending'] - youtube_data['date_published']\n",
    "\n",
    "# Covert category IDs to catetory names\n",
    "youtube_data['categoryId'].replace(lookup['categoryId'].tolist(), lookup['category'].tolist(), inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "new_names = {'channelTitle':'channel', 'categoryId':'category', 'view_count':'views', 'comment_count':'comments'}\n",
    "youtube_data.rename(columns = new_names, inplace=True)\n",
    "\n",
    "# Sort by likes\n",
    "youtube_data.sort_values('likes', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "# Reorder columns for readability\n",
    "new_order = ['channel', 'title', 'category', 'views', 'likes','dislikes','comments', 'date_published', 'date_trending','lag','month_published', 'month_trending', 'time_published','tags', 'description']\n",
    "youtube_data=youtube_data[new_order]\n",
    "\n",
    "# Get column names so they are handy\n",
    "cols = youtube_data.columns\n",
    "\n",
    "# Keep only the most popular posting of duplicate videos\n",
    "# I could maybe try to roll the stats for duplicates together,\n",
    "# but this is tricky, in that they will have different dates.\n",
    "youtube_data = youtube_data.drop_duplicates(subset='title', keep='first')\n",
    "youtube_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_published</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_published</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-03</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-05</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-06</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-08</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-31</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                number_published\n",
       "date_published                  \n",
       "2020-08-03                     1\n",
       "2020-08-05                     4\n",
       "2020-08-06                    22\n",
       "2020-08-07                    34\n",
       "2020-08-08                    29\n",
       "...                          ...\n",
       "2020-10-31                    32\n",
       "2020-11-01                    27\n",
       "2020-11-02                    37\n",
       "2020-11-03                    10\n",
       "2020-11-04                     2\n",
       "\n",
       "[93 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many videos were published each day in the dataset\n",
    "# Remember, the youtube data set is a subset of of trending videos in the US, not all videos\n",
    "pub_by_date = youtube_data[['title', 'date_published']].groupby('date_published')\\\n",
    ".count().rename(columns={'title':'number_published'})\n",
    "pub_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pub_by_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# And plot the number published each day\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# I could see if there are trends by days of the week\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mpub_by_date\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_published\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pub_by_date' is not defined"
     ]
    }
   ],
   "source": [
    "# And plot the number published each day\n",
    "# I could see if there are trends by days of the week\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(pub_by_date['number_published'])\n",
    "plt.xticks(rotation=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories looks at total published, likes, and dislikes.\n",
    "# Only the news and politics have significant dislikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of vids in each category\n",
    "# Someone could add the x labels.  I'm bad at it.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there are any trends by month.\n",
    "# There are not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See how long it takes a video to trend.\n",
    "# We have a single outlier at 30 days, which we could chop off in subsequent work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Month for most liked videos (Aug, Sept, Oct, Nov)?aug\n",
      "How many videos to see?3358\n",
      "Most popular videos:\n",
      "Series([], Name: title, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Produce the most popular videos for a user\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Process with Matplotlib/Pandas:\n",
    "* Using the previously created PANDAS dataframe, created additional layers to parse specific data per month,\n",
    "* This included trending categories and user statistics.\n",
    "* Added supplemental grouby functions to organize this data. \n",
    "* Create bar and scatter graphs using pyplot. \n",
    "* The heatmap was created with a correlation function and seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coorelation between youtube scrubbed dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coorelation heatmap using Seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Channel Views by Trending Month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify Top Trending Channels by Month for August\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify Top Trending Channels by Month for September\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify Top Trending Channels by Month for October\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify Top Trending Channels by Month for November\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph August\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph September\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph October\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph November\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep\n",
    "#create columns of percentage of likes and dislikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep\n",
    "#df of the top 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plots of likes and dislikes on a date from all four months based on views\n",
    "#not 100% convinced scatter plots work for this\n",
    "#August starts on the 13th, full month of Sept and Oct, Nov is only 1-5th\n",
    "\n",
    "#input_date = input(f'Enter a date to see what was trending that day example month/day/year')\n",
    "#date=df[df['date_trending']==input_date]\n",
    "\n",
    "#subplots initilizer\n",
    "\n",
    "\n",
    "#supplot 1\n",
    "#initialize\n",
    "\n",
    "#filter by specific day\n",
    "\n",
    "#subplot (rows, columns, locate)\n",
    "\n",
    "\n",
    "#subplot 2\n",
    "#initialize\n",
    "\n",
    "#filter by specific day\n",
    "\n",
    "#subplot (rows, columns, locate)\n",
    "\n",
    "\n",
    "\n",
    "#subplot 3\n",
    "#initialize\n",
    "\n",
    "#filter by specific day\n",
    "\n",
    "#subplot (rows, columns, locate)\n",
    "\n",
    "\n",
    "#subplot 4\n",
    "#initialize\n",
    "\n",
    "#filter by specific day\n",
    "\n",
    "#subplot (rows, columns, locate)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plots likes, dislikes and comments per category based on views\n",
    "#top 8 categorys\n",
    "#subplots initilizer\n",
    " \n",
    "\n",
    "\n",
    "#subplot 2\n",
    " \n",
    "\n",
    "\n",
    "#subplot 3\n",
    "#initialize\n",
    "\n",
    "#subplot 4\n",
    "#initialize\n",
    "\n",
    "\n",
    "\n",
    "#subplot 5\n",
    "#initialize\n",
    "\n",
    "\n",
    "#subplot 6\n",
    "#initialize\n",
    "\n",
    "\n",
    "\n",
    "#subplot 7\n",
    "#initialize\n",
    " \n",
    "\n",
    "\n",
    "#subplot 8\n",
    "#initialize\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discord analsys: Shows reactions based on percet likes/dislikes if key term found in titles \n",
    "#subplots initilizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User input key term search to see percentage likes and dislikes for a key term\n",
    "#subplots initilizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subplots initilizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter of reactions of top 100 views and percent of likes and dislikes\n",
    "#subplots initilizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORING YOUTUBE API:\n",
    "* Collect data sample from YouTube API that contains top 50 most viewed YouTube videos in a month of 2019 and 2020.\n",
    "* Also specifically look for top 50 Quarantine Challenges by view count during strict COVID Lockdown in US.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Exploration Process:\n",
    "#### There are three kinds of data searches used: \n",
    "  * YouTube search, items with snippet descriptions\n",
    "  * YouTube video, to get video statistics\n",
    "  * youtube channel, to get channel statistic\n",
    "  * all the above three files all linked by the unique video_id and channel_id field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant videos on youtube in April 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookthrough youtube api and get top 50 relevant videos published between in April 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Process:\n",
    "   #### Once we pulled the necessary data:\n",
    "   * Stored the API data collected to a local folder so no need to run API everytime\n",
    "   * Create dataframs \n",
    "   * Merge data sets based on the video ID and channel ID fields. \n",
    "   * Sorted  the data based on view count, number of likes and dislikes. \n",
    "   * Rename and rearrange for better readablility\n",
    "   * Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant videos on youtube in April 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookthrough youtube api and get top 50 relevant videos published in April 2020\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    "* Create dataframs \n",
    "* Rename and rearrange for better readablility\n",
    "* Mearge and drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_video_ids, unpacks the dictionary stored in \"id\" and creats a data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = '' \n",
    "stopwords = set(STOPWORDS) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 50 Quarantine Challenges:\n",
    "* During strict lockdown(03/15/2020 through 06/15/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#youtube, looking through youtube api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    "* Create dataframs \n",
    "* Rename and rearrange for better readablility\n",
    "* Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_video_ids, unpacks the dictionary stored in \"id\" and creats a data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat a df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_viewed = top10_qc\n",
    "# Top quarantine challenge videos by view count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create wordcloud \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
